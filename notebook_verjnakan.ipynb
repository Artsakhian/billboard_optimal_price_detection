{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9bc73170",
      "metadata": {
        "id": "9bc73170"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Activation, Input, concatenate, Reshape, Flatten\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOJtWzg1iz5z",
        "outputId": "b1580c13-348b-4642-9d2a-f6e21bdf6768"
      },
      "id": "aOJtWzg1iz5z",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Optimal Price Detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f4IQxJji9dy",
        "outputId": "a49c7b87-d60d-4dbd-bb1d-117de0670064"
      },
      "id": "0f4IQxJji9dy",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Optimal Price Detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c52c70d5",
      "metadata": {
        "id": "c52c70d5"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('data.csv')\n",
        "price = pd.read_csv('daily_price.csv').iloc[:, 1:]\n",
        "coef = pd.read_csv('booking_ratio.csv').iloc[:, 1:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_df = pd.read_csv('benchmark_data.csv')"
      ],
      "metadata": {
        "id": "SvU3tafap6s0"
      },
      "id": "SvU3tafap6s0",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding size column\n",
        "weights = {'small': 1, 'medium':2, 'large':3}\n",
        "data['Size'] = data['Size'].replace(weights)\n",
        "benchmark_df['Size'] = benchmark_df['Size'].replace(weights)"
      ],
      "metadata": {
        "id": "I2jwv_XGlKpe"
      },
      "id": "I2jwv_XGlKpe",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_lstm_benchmark = benchmark_df.iloc[:, 4:].applymap(func=lambda row: float(eval(row)[0])).astype(float)\n",
        "X_dense_benchmark = benchmark_df.iloc[:, :4]\n",
        "\n",
        "X_lstm_benchmark = X_lstm_benchmark.to_numpy().reshape(X_lstm_benchmark.shape[0], 520, 1)\n",
        "X_dense_benchmark = X_dense_benchmark.to_numpy().reshape(X_dense_benchmark.shape[0], 4, 1)\n",
        "\n",
        "X_lstm_benchmark = torch.tensor(X_lstm_benchmark).float()\n",
        "X_dense_benchmark = torch.tensor(X_dense_benchmark).float()"
      ],
      "metadata": {
        "id": "sLl-EGEZtAEb"
      },
      "id": "sLl-EGEZtAEb",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_lstm_benchmark = torch.tensor(X_lstm_benchmark)\n",
        "X_dense_benchmark = torch.tensor(X_dense_benchmark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMyP0EziKrq1",
        "outputId": "d113dec1-1eaf-4969-d0d3-be48b7b20c58"
      },
      "id": "nMyP0EziKrq1",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-9897c84e10ba>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_lstm_benchmark = torch.tensor(X_lstm_benchmark)\n",
            "<ipython-input-10-9897c84e10ba>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_dense_benchmark = torch.tensor(X_dense_benchmark)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dense data\n",
        "X_train_dense, X_test_dense, _ , _ = train_test_split(data.iloc[:, :4], coef)\n",
        "\n",
        "# Normalizing, before converting to numpy array\n",
        "lat_long_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "X_train_dense.iloc[:, 0] = lat_long_scaler.fit_transform(X_train_dense.iloc[:, 0].values.reshape(-1, 1))\n",
        "X_train_dense.iloc[:, 1] = lat_long_scaler.fit_transform(X_train_dense.iloc[:, 0].values.reshape(-1, 1))\n",
        "\n",
        "X_train_dense = X_train_dense.to_numpy().reshape(X_train_dense.shape[0], 4, 1)\n",
        "X_test_dense = X_test_dense.to_numpy().reshape(X_test_dense.shape[0], 4, 1)"
      ],
      "metadata": {
        "id": "BuAlJP8ZycMh"
      },
      "id": "BuAlJP8ZycMh",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM data\n",
        "X_train, X_test, y_train, y_test = train_test_split(price, coef)\n",
        "\n",
        "# Normalizing, before converting to numpy array\n",
        "scaler = MinMaxScaler()\n",
        "X_train_lstm = scaler.fit_transform(X_train.values)\n",
        "\n",
        "X_train_lstm = X_train.to_numpy().reshape(X_train.shape[0], 520, 1)\n",
        "y_train = y_train.to_numpy().reshape(y_train.shape[0], 520, 1)\n",
        "X_test_lstm = X_test.to_numpy().reshape(X_test.shape[0], 520, 1)\n",
        "y_test = y_test.to_numpy().reshape(y_test.shape[0], 520, 1)\n"
      ],
      "metadata": {
        "id": "JdZYXUQb297B"
      },
      "id": "JdZYXUQb297B",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_lstm = torch.tensor(X_train_lstm).float()\n",
        "X_train_dense = torch.tensor(X_train_dense).float()\n",
        "y_train = torch.tensor(y_train).float()\n",
        "y_test = torch.tensor(y_test).float()\n",
        "X_test_lstm = torch.tensor(X_test_lstm).float()\n",
        "X_test_dense = torch.tensor(X_test_dense).float()"
      ],
      "metadata": {
        "id": "bkLG1g4jpjxJ"
      },
      "id": "bkLG1g4jpjxJ",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm1 = nn.LSTM(input_size=520, hidden_size=260, num_layers=1, batch_first=True)\n",
        "        self.activation1 = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm1(x)\n",
        "        out = self.activation1(out)\n",
        "        return out[:, -1, :]  # Taking only the last time step's output\n",
        "# Define the dense neural network\n",
        "class DenseModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DenseModel, self).__init__()\n",
        "        self.dense1 = nn.Linear(1, 4)\n",
        "        self.activation1 = nn.ReLU()\n",
        "        self.dense2 = nn.Linear(4, 128)\n",
        "        self.activation2 = nn.ReLU()\n",
        "        self.dense3 = nn.Linear(128, 128)\n",
        "        self.activation3 = nn.ReLU()\n",
        "        self.dense4 = nn.Linear(128, 260)\n",
        "    def forward(self, x):\n",
        "        out = self.dense1(x)\n",
        "        out = self.activation1(out)\n",
        "        out = self.dense2(out)\n",
        "        out = self.activation2(out)\n",
        "        out = self.dense3(out)\n",
        "        out = self.activation3(out)\n",
        "        out = self.dense4(out)\n",
        "        return out[:, -1, :]\n",
        "class CombinedModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CombinedModel, self).__init__()\n",
        "        self.lstm_model = LSTMModel()\n",
        "        self.dense_model = DenseModel()\n",
        "    def forward(self, lstm_input, dense_input):\n",
        "        lstm_output = self.lstm_model(lstm_input)\n",
        "        dense_output = self.dense_model(dense_input)\n",
        "        combined_output = torch.cat((lstm_output, dense_output), dim=1)\n",
        "        return combined_output\n",
        "    def evaluate(self, inputs, labels):\n",
        "        lstm_input, dense_input = inputs\n",
        "        outputs = self.forward(lstm_input, dense_input)\n",
        "        loss = criterion(outputs, labels.squeeze(dim=2))\n",
        "        return outputs, loss\n",
        "    def predict(self, inputs):\n",
        "        lstm_input, dense_input = inputs\n",
        "        outputs = self.forward(lstm_input, dense_input)\n",
        "        return outputs\n",
        "\n",
        "combined_model = CombinedModel()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(combined_model.parameters(), lr=0.001)\n",
        "\n",
        "# batch_size = 64\n",
        "# num_epochs = 30\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     for i in range(0, len(X_train_lstm), batch_size):\n",
        "#         lstm_batch = X_train_lstm[i:i+batch_size]\n",
        "#         dense_batch = X_train_dense[i:i+batch_size]\n",
        "#         labels_batch = y_train[i:i+batch_size]\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = combined_model(lstm_batch, dense_batch)\n",
        "#         print(f'{i}/7500')\n",
        "#         loss = criterion(outputs, labels_batch.squeeze(dim=2))\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#     print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "-kQoxNup92dv"
      },
      "id": "-kQoxNup92dv",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uploading our trained model\n",
        "loaded_model = CombinedModel()\n",
        "loaded_model.load_state_dict(torch.load('combined_model_0-1240-loss-best.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYhbLW3USpfn",
        "outputId": "e15efd50-95e6-469a-f79a-35a3adb0a9fa"
      },
      "id": "GYhbLW3USpfn",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction, loss = loaded_model.evaluate([X_lstm_benchmark, X_dense_benchmark], torch.Tensor(2000, 520, 1))"
      ],
      "metadata": {
        "id": "sU5NAC5wJTQ8"
      },
      "id": "sU5NAC5wJTQ8",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_prices = np.zeros((2000,520))\n",
        "for i in range(520):\n",
        "    generated_prices[::, i] = 100 / 520 * i\n",
        "\n",
        "optimal_prices = (prediction * torch.Tensor(generated_prices)).detach().numpy().argmax(axis=1)"
      ],
      "metadata": {
        "id": "n8Oe4DQANUHi"
      },
      "id": "n8Oe4DQANUHi",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = []\n",
        "for generated_price, index in zip(generated_prices, optimal_prices):\n",
        "    optimal_price = generated_price[index]\n",
        "    result.append(optimal_price)"
      ],
      "metadata": {
        "id": "xIGXusniPHFi"
      },
      "id": "xIGXusniPHFi",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = np.array(result)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM5JEH62Pv-z",
        "outputId": "3c0b5745-570d-4bf5-a1ea-fad75b8a5810"
      },
      "id": "QM5JEH62Pv-z",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([91.15384615, 99.42307692, 99.42307692, ..., 91.15384615,\n",
              "       99.42307692, 99.42307692])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('optimal_prices.npy', result)\n",
        "np.savetxt('optimal_prices.txt', result)"
      ],
      "metadata": {
        "id": "_wTn4-fwQm4j"
      },
      "id": "_wTn4-fwQm4j",
      "execution_count": 51,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}